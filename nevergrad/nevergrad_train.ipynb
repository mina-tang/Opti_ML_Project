{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "import nevergrad as ng\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"nevergrad/\")\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from models import CNN_Simple,All_CNN_C,VAE,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainManager:\n",
    "    def __init__(self, model, dataloader_train, dataloader_test, loss, device, isLSTM=False):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.best_model = None\n",
    "        self.dataloader_train = dataloader_train\n",
    "        self.dataloader_test = dataloader_test\n",
    "        self.best_score = 1e9\n",
    "        self.loss = loss\n",
    "        self.epoch = 1\n",
    "        self.n_samples = len(dataloader_train)\n",
    "        self.iteration = 0\n",
    "        self.test_losses = []\n",
    "        self.train_losses = []\n",
    "        self.accuracy = []\n",
    "        # self.best_output = []\n",
    "        # self.LSTM = isLSTM\n",
    "            \n",
    "    def evaluate(self, model):\n",
    "        # Assume that test loader contains only one batch\n",
    "        test_inputs, test_labels = next(iter(self.dataloader_test))\n",
    "        predicted = model(test_inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.loss(predicted, test_labels.flatten())\n",
    "\n",
    "        predicted_labels = torch.argmax(predicted, axis=1)\n",
    "        accuracy = torch.sum(test_labels.flatten() == predicted_labels) / len(predicted)\n",
    "        \n",
    "        return loss.item(), accuracy\n",
    "\n",
    "\n",
    "    def cost_function(self, parameters):\n",
    "        load_params(self.model, torch.tensor(parameters))\n",
    "        \n",
    "        # Load the next batch\n",
    "        inputs, labels = next(iter(self.dataloader_train))\n",
    "        \n",
    "        predicted = self.model(inputs).to(device)\n",
    "        loss = self.loss(predicted, labels.flatten()).item()\n",
    "\n",
    "        test_loss, accuracy = self.evaluate(self.model)\n",
    "        if self.best_score > test_loss :\n",
    "            self.best_score = test_loss\n",
    "            self.best_model = copy.deepcopy(self.model)\n",
    "\n",
    "        print(f'epoch {self.epoch}; test loss function : {test_loss}, accuracy: {accuracy:.2f} best score : {self.best_score}')\n",
    "        \n",
    "        self.iteration += 1\n",
    "\n",
    "        self.test_losses.append(test_loss)\n",
    "        self.train_losses.append(loss)\n",
    "        self.accuracy.append(accuracy)\n",
    "\n",
    "        if self.iteration % self.n_samples == 0: \n",
    "            self.epoch += 1\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(model, param_tensor):\n",
    "    current_index = 0\n",
    "    for param in model.parameters():\n",
    "        param_length = param.numel()\n",
    "        param.data = param_tensor[current_index:current_index + param_length].reshape(param.size()).to(device)\n",
    "        current_index += param_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P0 : wine (small model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(11, 32).to(dtype=torch.double)\n",
    "        self.relu1 = nn.GELU()\n",
    "        self.fc2 = nn.Linear(32, 32).to(dtype=torch.double)\n",
    "        self.relu2 = nn.GELU()\n",
    "        self.fc3 = nn.Linear(32, n_classes)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class create_dataset(Dataset):\n",
    "    def __init__(self, data, data_classes):\n",
    "        self.data = data\n",
    "        self.data_classes = data_classes\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.from_numpy(self.data.iloc[index][:-1].to_numpy())\n",
    "        \n",
    "        label = self.data.iloc[index][-1:].to_numpy()[0]\n",
    "        y = np.where(data_classes == label)[0]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "# data = pd.read_csv(\"data/winequality-red.csv\", sep=\";\")\n",
    "\n",
    "wine_quality  = fetch_ucirepo(id=186)\n",
    "data_inputs = wine_quality.data.features\n",
    "data_outputs = wine_quality.data.targets\n",
    "\n",
    "data = pd.concat([data_inputs, data_outputs], axis=1)\n",
    "\n",
    "data_train, data_test = train_test_split(data, test_size=0.25)\n",
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "columns_to_normalize = data_train.columns[data_train.columns != \"quality\"].tolist()\n",
    "data_train[columns_to_normalize] = scaler.fit_transform(data_train[columns_to_normalize])\n",
    "data_test[columns_to_normalize] = scaler.transform(data_test[columns_to_normalize])\n",
    "\n",
    "data_classes = np.sort(data[\"quality\"].unique())\n",
    "\n",
    "dataset_train = create_dataset(data_train, data_classes)\n",
    "dataset_test  = create_dataset(data_test, data_classes)\n",
    "training_loader = DataLoader(dataset_train, batch_size=len(data_train), shuffle=True)\n",
    "validation_loader = DataLoader(dataset_test, batch_size=len(data_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1625\n"
     ]
    }
   ],
   "source": [
    "print(type(data_classes))\n",
    "#print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_weights(data_train_quality, data_classes):\n",
    "    count = np.zeros(data_classes.shape)\n",
    "\n",
    "    for label in data_train_quality:\n",
    "        y = np.where(data_classes == label)[0]\n",
    "        count[y] += 1\n",
    "    \n",
    "    weights = 1 / count\n",
    "    weights = weights / np.sum(weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(data_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Net().to(device)\n",
    "# trainer = TrainManager(model, training_loader, validation_loader, loss, device)\n",
    "# plt.hist(next(iter(trainer.model.parameters())).flatten().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; test loss function : 1.934360769556317, accuracy: 0.32 best score : 1.934360769556317\n",
      "epoch 2; test loss function : 2.13039592374192, accuracy: 0.04 best score : 1.934360769556317\n",
      "epoch 3; test loss function : 1.9585733050047656, accuracy: 0.21 best score : 1.934360769556317\n",
      "epoch 4; test loss function : 1.914087189832237, accuracy: 0.25 best score : 1.914087189832237\n",
      "epoch 5; test loss function : 1.879021313334073, accuracy: 0.29 best score : 1.879021313334073\n",
      "epoch 6; test loss function : 1.8311758355526169, accuracy: 0.33 best score : 1.8311758355526169\n",
      "epoch 7; test loss function : 2.063204392686945, accuracy: 0.10 best score : 1.8311758355526169\n",
      "epoch 8; test loss function : 1.8964755200312473, accuracy: 0.27 best score : 1.8311758355526169\n",
      "epoch 9; test loss function : 2.0760875479591805, accuracy: 0.09 best score : 1.8311758355526169\n",
      "epoch 10; test loss function : 2.052066050719096, accuracy: 0.11 best score : 1.8311758355526169\n",
      "epoch 11; test loss function : 1.9124844545113335, accuracy: 0.25 best score : 1.8311758355526169\n",
      "epoch 12; test loss function : 2.005898446367688, accuracy: 0.16 best score : 1.8311758355526169\n",
      "epoch 13; test loss function : 1.8923269248052423, accuracy: 0.27 best score : 1.8311758355526169\n",
      "epoch 14; test loss function : 1.8366895039650644, accuracy: 0.33 best score : 1.8311758355526169\n",
      "epoch 15; test loss function : 1.9280319829788635, accuracy: 0.24 best score : 1.8311758355526169\n",
      "epoch 16; test loss function : 1.8333449935821986, accuracy: 0.33 best score : 1.8311758355526169\n",
      "epoch 17; test loss function : 1.8081176256530838, accuracy: 0.36 best score : 1.8081176256530838\n",
      "epoch 18; test loss function : 2.0602552079765326, accuracy: 0.11 best score : 1.8081176256530838\n",
      "epoch 19; test loss function : 1.9105962663529958, accuracy: 0.25 best score : 1.8081176256530838\n",
      "epoch 20; test loss function : 1.8417330162725722, accuracy: 0.32 best score : 1.8081176256530838\n",
      "epoch 21; test loss function : 1.8435525109760935, accuracy: 0.32 best score : 1.8081176256530838\n",
      "epoch 22; test loss function : 1.8699927119284148, accuracy: 0.30 best score : 1.8081176256530838\n",
      "epoch 23; test loss function : 1.7341259888400127, accuracy: 0.43 best score : 1.7341259888400127\n",
      "epoch 24; test loss function : 1.7906471399642794, accuracy: 0.37 best score : 1.7341259888400127\n",
      "epoch 25; test loss function : 1.785096092787413, accuracy: 0.38 best score : 1.7341259888400127\n",
      "epoch 26; test loss function : 1.876622264995443, accuracy: 0.29 best score : 1.7341259888400127\n",
      "epoch 27; test loss function : 1.7408067442062947, accuracy: 0.42 best score : 1.7341259888400127\n",
      "epoch 28; test loss function : 1.7967732897565751, accuracy: 0.37 best score : 1.7341259888400127\n",
      "epoch 29; test loss function : 1.718037568612414, accuracy: 0.45 best score : 1.718037568612414\n",
      "epoch 30; test loss function : 1.7684942321255877, accuracy: 0.40 best score : 1.718037568612414\n",
      "epoch 31; test loss function : 1.726652949716365, accuracy: 0.44 best score : 1.718037568612414\n",
      "epoch 32; test loss function : 1.756138455105957, accuracy: 0.41 best score : 1.718037568612414\n",
      "epoch 33; test loss function : 1.7752462111003795, accuracy: 0.39 best score : 1.718037568612414\n",
      "epoch 34; test loss function : 1.7518815276184259, accuracy: 0.41 best score : 1.718037568612414\n",
      "epoch 35; test loss function : 1.7182168263847146, accuracy: 0.45 best score : 1.718037568612414\n",
      "epoch 36; test loss function : 1.8226531048337575, accuracy: 0.34 best score : 1.718037568612414\n",
      "epoch 37; test loss function : 1.7498415876127844, accuracy: 0.42 best score : 1.718037568612414\n",
      "epoch 38; test loss function : 1.747597880698959, accuracy: 0.42 best score : 1.718037568612414\n",
      "epoch 39; test loss function : 1.7266528490136455, accuracy: 0.44 best score : 1.718037568612414\n",
      "epoch 40; test loss function : 1.710652949692636, accuracy: 0.45 best score : 1.710652949692636\n",
      "epoch 41; test loss function : 1.9364986027002085, accuracy: 0.23 best score : 1.710652949692636\n",
      "epoch 42; test loss function : 1.7734196601842205, accuracy: 0.39 best score : 1.710652949692636\n",
      "epoch 43; test loss function : 1.7254221804856038, accuracy: 0.44 best score : 1.710652949692636\n",
      "epoch 44; test loss function : 1.7100815470252948, accuracy: 0.46 best score : 1.7100815470252948\n",
      "epoch 45; test loss function : 1.740189903904998, accuracy: 0.43 best score : 1.7100815470252948\n",
      "epoch 46; test loss function : 1.7075685862074679, accuracy: 0.46 best score : 1.7075685862074679\n",
      "epoch 47; test loss function : 1.7057262509242592, accuracy: 0.46 best score : 1.7057262509242592\n",
      "epoch 48; test loss function : 1.7591340529715551, accuracy: 0.41 best score : 1.7057262509242592\n",
      "epoch 49; test loss function : 1.6960326675109334, accuracy: 0.47 best score : 1.6960326675109334\n",
      "epoch 50; test loss function : 1.726021092598272, accuracy: 0.44 best score : 1.6960326675109334\n",
      "epoch 51; test loss function : 1.7568065553160432, accuracy: 0.41 best score : 1.6960326675109334\n",
      "epoch 52; test loss function : 1.7746529496992307, accuracy: 0.39 best score : 1.6960326675109334\n",
      "epoch 53; test loss function : 1.7340375679153852, accuracy: 0.43 best score : 1.6960326675109334\n",
      "epoch 54; test loss function : 1.7481597818198582, accuracy: 0.42 best score : 1.6960326675109334\n",
      "epoch 55; test loss function : 1.7189777617944946, accuracy: 0.45 best score : 1.6960326675109334\n",
      "epoch 56; test loss function : 1.694085773635782, accuracy: 0.47 best score : 1.694085773635782\n",
      "epoch 57; test loss function : 1.7023256279198686, accuracy: 0.46 best score : 1.694085773635782\n",
      "epoch 58; test loss function : 1.7170426905045388, accuracy: 0.45 best score : 1.694085773635782\n",
      "epoch 59; test loss function : 1.700188471794504, accuracy: 0.47 best score : 1.694085773635782\n",
      "epoch 60; test loss function : 1.7008246441933503, accuracy: 0.46 best score : 1.694085773635782\n",
      "epoch 61; test loss function : 1.6960741799330679, accuracy: 0.47 best score : 1.694085773635782\n",
      "epoch 62; test loss function : 1.706961945720194, accuracy: 0.46 best score : 1.694085773635782\n",
      "epoch 63; test loss function : 1.7112670611018173, accuracy: 0.45 best score : 1.694085773635782\n",
      "epoch 64; test loss function : 1.7031371701296985, accuracy: 0.46 best score : 1.694085773635782\n",
      "epoch 65; test loss function : 1.6971180930511314, accuracy: 0.47 best score : 1.694085773635782\n",
      "epoch 66; test loss function : 1.7014566700672396, accuracy: 0.46 best score : 1.694085773635782\n",
      "epoch 67; test loss function : 1.6921976558833622, accuracy: 0.47 best score : 1.6921976558833622\n",
      "epoch 68; test loss function : 1.6933990359258038, accuracy: 0.47 best score : 1.6921976558833622\n",
      "epoch 69; test loss function : 1.6878837189471338, accuracy: 0.48 best score : 1.6878837189471338\n",
      "epoch 70; test loss function : 1.7045018454658087, accuracy: 0.46 best score : 1.6878837189471338\n",
      "epoch 71; test loss function : 1.6971132696730324, accuracy: 0.47 best score : 1.6878837189471338\n",
      "epoch 72; test loss function : 1.6964951572885771, accuracy: 0.47 best score : 1.6878837189471338\n",
      "epoch 73; test loss function : 1.6938621148334505, accuracy: 0.47 best score : 1.6878837189471338\n",
      "epoch 74; test loss function : 1.6866523746328892, accuracy: 0.48 best score : 1.6866523746328892\n",
      "epoch 75; test loss function : 1.6953796297034218, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 76; test loss function : 1.7000214620494074, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 77; test loss function : 1.6940366153721245, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 78; test loss function : 1.6940376210875223, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 79; test loss function : 1.6940375650778587, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 80; test loss function : 1.690960647648325, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 81; test loss function : 1.6946529499147247, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 82; test loss function : 1.689729872913465, accuracy: 0.48 best score : 1.6866523746328892\n",
      "epoch 83; test loss function : 1.6923545875371837, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 84; test loss function : 1.6964991044820674, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 85; test loss function : 1.6915200561208363, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 86; test loss function : 1.6903453210595816, accuracy: 0.48 best score : 1.6866523746328892\n",
      "epoch 87; test loss function : 1.6876919551056184, accuracy: 0.48 best score : 1.6866523746328892\n",
      "epoch 88; test loss function : 1.6928068158878529, accuracy: 0.47 best score : 1.6866523746328892\n",
      "epoch 89; test loss function : 1.6842096103279778, accuracy: 0.48 best score : 1.6842096103279778\n",
      "epoch 90; test loss function : 1.6772100473922922, accuracy: 0.49 best score : 1.6772100473922922\n",
      "epoch 91; test loss function : 1.6842417486682493, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 92; test loss function : 1.6794526533274303, accuracy: 0.49 best score : 1.6772100473922922\n",
      "epoch 93; test loss function : 1.7099256475327256, accuracy: 0.46 best score : 1.6772100473922922\n",
      "epoch 94; test loss function : 1.7623093407624437, accuracy: 0.40 best score : 1.6772100473922922\n",
      "epoch 95; test loss function : 1.711883718947134, accuracy: 0.45 best score : 1.6772100473922922\n",
      "epoch 96; test loss function : 1.7088067754105578, accuracy: 0.46 best score : 1.6772100473922922\n",
      "epoch 97; test loss function : 1.7130518344760082, accuracy: 0.45 best score : 1.6772100473922922\n",
      "epoch 98; test loss function : 1.6977298727888008, accuracy: 0.47 best score : 1.6772100473922922\n",
      "epoch 99; test loss function : 1.7007993950745948, accuracy: 0.46 best score : 1.6772100473922922\n",
      "epoch 100; test loss function : 1.682646262885762, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 101; test loss function : 1.7069271727775859, accuracy: 0.46 best score : 1.6772100473922922\n",
      "epoch 102; test loss function : 1.7149606420227115, accuracy: 0.45 best score : 1.6772100473922922\n",
      "epoch 103; test loss function : 1.6848067615840185, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 104; test loss function : 1.7426525044578878, accuracy: 0.42 best score : 1.6772100473922922\n",
      "epoch 105; test loss function : 1.6995816611325032, accuracy: 0.47 best score : 1.6772100473922922\n",
      "epoch 106; test loss function : 1.7260435391280498, accuracy: 0.44 best score : 1.6772100473922922\n",
      "epoch 107; test loss function : 1.6977406928730037, accuracy: 0.47 best score : 1.6772100473922922\n",
      "epoch 108; test loss function : 1.6924276197199717, accuracy: 0.47 best score : 1.6772100473922922\n",
      "epoch 109; test loss function : 1.740098779560278, accuracy: 0.43 best score : 1.6772100473922922\n",
      "epoch 110; test loss function : 1.7261504165883053, accuracy: 0.44 best score : 1.6772100473922922\n",
      "epoch 111; test loss function : 1.6958774799165997, accuracy: 0.47 best score : 1.6772100473922922\n",
      "epoch 112; test loss function : 1.689749729945063, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 113; test loss function : 1.6848173208290598, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 114; test loss function : 1.745117046921166, accuracy: 0.42 best score : 1.6772100473922922\n",
      "epoch 115; test loss function : 1.7272709925829166, accuracy: 0.44 best score : 1.6772100473922922\n",
      "epoch 116; test loss function : 1.7414222314100405, accuracy: 0.42 best score : 1.6772100473922922\n",
      "epoch 117; test loss function : 1.6878824377252086, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 118; test loss function : 1.6952688164521466, accuracy: 0.47 best score : 1.6772100473922922\n",
      "epoch 119; test loss function : 1.684806794844127, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 120; test loss function : 1.703342266479926, accuracy: 0.46 best score : 1.6772100473922922\n",
      "epoch 121; test loss function : 1.6915760266391513, accuracy: 0.47 best score : 1.6772100473922922\n",
      "epoch 122; test loss function : 1.6958791792673433, accuracy: 0.47 best score : 1.6772100473922922\n",
      "epoch 123; test loss function : 1.6860068325188236, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 124; test loss function : 1.6780397447652884, accuracy: 0.49 best score : 1.6772100473922922\n",
      "epoch 125; test loss function : 1.6848048063063639, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 126; test loss function : 1.6836287333875282, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 127; test loss function : 1.6866463593353076, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 128; test loss function : 1.6878822209693223, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 129; test loss function : 1.6781588854748632, accuracy: 0.49 best score : 1.6772100473922922\n",
      "epoch 130; test loss function : 1.6792683343093098, accuracy: 0.49 best score : 1.6772100473922922\n",
      "epoch 131; test loss function : 1.6848070282221823, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 132; test loss function : 1.6884995373162788, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 133; test loss function : 1.6810282759346307, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 134; test loss function : 1.688556276178847, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 135; test loss function : 1.6797676934912613, accuracy: 0.49 best score : 1.6772100473922922\n",
      "epoch 136; test loss function : 1.681551763955622, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 137; test loss function : 1.68296063117245, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 138; test loss function : 1.6872683343316934, accuracy: 0.48 best score : 1.6772100473922922\n",
      "epoch 139; test loss function : 1.6761911622104357, accuracy: 0.49 best score : 1.6761911622104357\n",
      "epoch 140; test loss function : 1.681735580286376, accuracy: 0.48 best score : 1.6761911622104357\n",
      "epoch 141; test loss function : 1.6847818357746238, accuracy: 0.48 best score : 1.6761911622104357\n",
      "epoch 142; test loss function : 1.6878300269030646, accuracy: 0.48 best score : 1.6761911622104357\n",
      "epoch 143; test loss function : 1.6836379467404972, accuracy: 0.48 best score : 1.6761911622104357\n",
      "epoch 144; test loss function : 1.682733263161097, accuracy: 0.48 best score : 1.6761911622104357\n",
      "epoch 145; test loss function : 1.6792683342992991, accuracy: 0.49 best score : 1.6761911622104357\n",
      "epoch 146; test loss function : 1.6727637147269359, accuracy: 0.49 best score : 1.6727637147269359\n",
      "epoch 147; test loss function : 1.6817258461397229, accuracy: 0.48 best score : 1.6727637147269359\n",
      "epoch 148; test loss function : 1.6638837156998223, accuracy: 0.50 best score : 1.6638837156998223\n",
      "epoch 149; test loss function : 1.6952684560866116, accuracy: 0.47 best score : 1.6638837156998223\n",
      "epoch 150; test loss function : 1.6798832016512832, accuracy: 0.49 best score : 1.6638837156998223\n",
      "epoch 151; test loss function : 1.662671790599467, accuracy: 0.50 best score : 1.662671790599467\n",
      "epoch 152; test loss function : 1.6878709424704843, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 153; test loss function : 1.6921914030480993, accuracy: 0.47 best score : 1.662671790599467\n",
      "epoch 154; test loss function : 1.7241914112548509, accuracy: 0.44 best score : 1.662671790599467\n",
      "epoch 155; test loss function : 1.6940976363668006, accuracy: 0.47 best score : 1.662671790599467\n",
      "epoch 156; test loss function : 1.6853118557837794, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 157; test loss function : 1.694648597173932, accuracy: 0.47 best score : 1.662671790599467\n",
      "epoch 158; test loss function : 1.6737078806788723, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 159; test loss function : 1.6861601703438442, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 160; test loss function : 1.748194682796114, accuracy: 0.42 best score : 1.662671790599467\n",
      "epoch 161; test loss function : 1.7014201334424828, accuracy: 0.46 best score : 1.662671790599467\n",
      "epoch 162; test loss function : 1.6743456959311473, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 163; test loss function : 1.6811149543148618, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 164; test loss function : 1.6811143290778023, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 165; test loss function : 1.6761752984928842, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 166; test loss function : 1.6773501616369098, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 167; test loss function : 1.6810913763633821, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 168; test loss function : 1.6742743335914467, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 169; test loss function : 1.6780105662319387, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 170; test loss function : 1.676192237396136, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 171; test loss function : 1.6731029337504468, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 172; test loss function : 1.673130328670898, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 173; test loss function : 1.6743385543239335, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 174; test loss function : 1.671870316010817, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 175; test loss function : 1.6749589148797255, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 176; test loss function : 1.6755763302470499, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 177; test loss function : 1.677421930107338, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 178; test loss function : 1.6725139597297407, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 179; test loss function : 1.6718838857595404, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 180; test loss function : 1.6731148259860311, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 181; test loss function : 1.6755393707921928, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 182; test loss function : 1.6741586767264998, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 183; test loss function : 1.673106708927746, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 184; test loss function : 1.6841888718840523, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 185; test loss function : 1.671883730812593, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 186; test loss function : 1.6893779084176734, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 187; test loss function : 1.6810724166114928, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 188; test loss function : 1.6761756515002735, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 189; test loss function : 1.6728421586616373, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 190; test loss function : 1.6783413607374387, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 191; test loss function : 1.6835348198414237, accuracy: 0.48 best score : 1.662671790599467\n",
      "epoch 192; test loss function : 1.6724986569157876, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 193; test loss function : 1.678037611969019, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 194; test loss function : 1.6755714166733362, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 195; test loss function : 1.676420942294853, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 196; test loss function : 1.6737476895811423, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 197; test loss function : 1.669997362582861, accuracy: 0.50 best score : 1.662671790599467\n",
      "epoch 198; test loss function : 1.6755826145091761, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 199; test loss function : 1.671908319819186, accuracy: 0.49 best score : 1.662671790599467\n",
      "epoch 200; test loss function : 1.6749330379764495, accuracy: 0.49 best score : 1.662671790599467\n"
     ]
    }
   ],
   "source": [
    "model = Net(len(data_classes)).to(device)\n",
    "#model.load_state_dict(torch.load('models/Net.pt'))\n",
    "\n",
    "# loss_weights = compute_loss_weights(data_train[\"quality\"], data_classes)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 200\n",
    "nb_batch = len(training_loader)\n",
    "trainer = TrainManager(model, training_loader, validation_loader, loss, device)\n",
    "fitness = trainer.cost_function\n",
    "\n",
    "# Compute number of parameters of the model + initialize parametrization\n",
    "init_params = torch.concatenate([p.data.flatten() for p in trainer.model.parameters()])\n",
    "parametrization = ng.p.Array(init=init_params)\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=parametrization, budget=epochs*nb_batch, num_workers=1)\n",
    "optimizer.a = 1e1\n",
    "learned_param = optimizer.minimize(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = []\n",
    "\n",
    "# epochs_space = np.linspace(0, epochs, len(trainer.train_losses))\n",
    "\n",
    "plt.scatter(range(0,len(trainer.accuracy)),trainer.accuracy, label=\"training\", alpha=0.5, marker='.' )\n",
    "#plt.plot(trainer.test_losses, label=\"test\", alpha=0.5)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "# plt.yscale(\"log\")\n",
    "plt.title(\"Training and testing loss as a function of epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3,  ..., 2, 3, 2])\n",
      "tensor([3, 3, 4,  ..., 3, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "test_inputs, test_labels = next(iter(validation_loader))\n",
    "predicted = trainer.best_model(test_inputs)\n",
    "predicted_labels = torch.argmax(predicted, axis=1)\n",
    "\n",
    "print(predicted_labels)\n",
    "print(test_labels.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Lambda(lambda x: x.double()),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "training_set = torchvision.datasets.FashionMNIST(\"./data\", train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST(\"./data\", train=False, transform=transform, download=True)\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=len(training_set)//1, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=len(validation_set)//1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Simple().to(device)\n",
    "torch.save(model.state_dict(), 'models/CNN_Simple.pt')\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restart here for another optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('models/CNN_Simple.pt'))\n",
    "\n",
    "epochs = 20\n",
    "nb_batch = len(training_loader)\n",
    "trainer = TrainManager(model,training_loader,validation_loader,loss,device)\n",
    "fitness = trainer.cost_function\n",
    "\n",
    "# Compute number of parameters of the model + initialize parametrization\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "parametrization = ng.p.Array(shape=(num_params,))\n",
    "optimizer = ng.optimizers.SPSA(parametrization=parametrization, budget=epochs*nb_batch)\n",
    "optimizer.a = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; test loss function : 2.381978772997349, accuracy: 0.16 best score : 2.381978772997349\n",
      "epoch 2; test loss function : 2.359716201906797, accuracy: 0.05 best score : 2.359716201906797\n",
      "epoch 3; test loss function : 2.3429220175965852, accuracy: 0.10 best score : 2.3429220175965852\n",
      "epoch 4; test loss function : 2.4067227657917973, accuracy: 0.10 best score : 2.3429220175965852\n",
      "epoch 5; test loss function : 2.318233420508853, accuracy: 0.10 best score : 2.318233420508853\n",
      "epoch 6; test loss function : 2.290868862926954, accuracy: 0.16 best score : 2.290868862926954\n",
      "epoch 7; test loss function : 2.2881525278665658, accuracy: 0.14 best score : 2.2881525278665658\n",
      "epoch 8; test loss function : 2.287223081779132, accuracy: 0.16 best score : 2.287223081779132\n",
      "epoch 9; test loss function : 2.313836605700281, accuracy: 0.12 best score : 2.287223081779132\n",
      "epoch 10; test loss function : 2.325525489977407, accuracy: 0.10 best score : 2.287223081779132\n",
      "epoch 11; test loss function : 2.3405073857670025, accuracy: 0.10 best score : 2.287223081779132\n",
      "epoch 12; test loss function : 2.314641522437657, accuracy: 0.14 best score : 2.287223081779132\n",
      "epoch 13; test loss function : 2.2910730659216014, accuracy: 0.12 best score : 2.287223081779132\n",
      "epoch 14; test loss function : 2.302066295018794, accuracy: 0.11 best score : 2.287223081779132\n",
      "epoch 15; test loss function : 2.3341991597209266, accuracy: 0.10 best score : 2.287223081779132\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m learned_param \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/nevergrad/optimization/base.py:678\u001b[0m, in \u001b[0;36mOptimizer.minimize\u001b[0;34m(self, objective_function, executor, batch_mode, verbosity, constraint_violation)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finished_jobs:\n\u001b[1;32m    677\u001b[0m     x, job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finished_jobs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m constraint_violation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    680\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell(\n\u001b[1;32m    681\u001b[0m             x, result, [f(x\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m constraint_violation]\n\u001b[1;32m    682\u001b[0m         )  \u001b[38;5;66;03m# TODO: this is not parallelized, wtf!\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/nevergrad/optimization/utils.py:145\u001b[0m, in \u001b[0;36mDelayedJob.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tp\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed:\n\u001b[0;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "Cell \u001b[0;32mIn[21], line 38\u001b[0m, in \u001b[0;36mTrainManager.cost_function\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Load the next batch\u001b[39;00m\n\u001b[1;32m     36\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_train))\n\u001b[0;32m---> 38\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(predicted, labels\u001b[38;5;241m.\u001b[39mflatten())\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     41\u001b[0m test_loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Opti_ML_Project/nevergrad/../models.py:16\u001b[0m, in \u001b[0;36mCNN_Simple.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/torch/nn/functional.py:1500\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learned_param = optimizer.minimize(fitness)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
